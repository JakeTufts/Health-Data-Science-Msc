{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3fdb796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jtbbl/Library/CloudStorage/OneDrive-UniversityofBirmingham/MSc Health Data Science/Mod 6 - Multi-Model/Presentation'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c579c440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaf9de6",
   "metadata": {},
   "source": [
    "# Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a95a6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data in\n",
    "raw_multi_model_df = pd.read_excel('Group Project v3.xlsx', sheet_name='Data', index_col='Sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0863f420",
   "metadata": {},
   "source": [
    "# Splitting data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df2652d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into the 3 datasets\n",
    "clinical_df = raw_multi_model_df.iloc[:,0:11]\n",
    "glycome_df = raw_multi_model_df.loc[:, 'Low-branching glycans (LB)':'Antennary fucosylation (AF)']\n",
    "scfa_df = raw_multi_model_df.loc[:, '2-hydroxybutyrate':'Valerate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9249cce",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe7238c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hc/c0m0nxk93qb_ggmlvbk7wtbh0000gn/T/ipykernel_48760/485087828.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clinical_df_clean['Age'][clinical_df_clean['Age']<18]=np.nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "No                                         196\n",
       "Epilepsy                                    10\n",
       "Hypertention                                 3\n",
       "High choles                                  2\n",
       "communicating hydrocephalus                  1\n",
       "Hypothyroidism                               1\n",
       "Hypertention, Drawsines, Disorientation      1\n",
       "Diabetes                                     1\n",
       "TB                                           1\n",
       "Aplastic A/high BP                           1\n",
       "IDDM                                         1\n",
       "Known case of hypertention                   1\n",
       "Paralysis befor 12 years                     1\n",
       "Name: Co-morbidities, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[156, 200]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data cleaning - Clinical data\n",
    "clinical_df_clean = clinical_df.copy()\n",
    "\n",
    "# Removing leading white space in Diarrhea\n",
    "clinical_df_clean['Diarrheal/ Non Diarrheal']=[i.strip() for i in clinical_df_clean['Diarrheal/ Non Diarrheal']]\n",
    "\n",
    "# A sample is 2 years old but cohort study (5 samples under 18)\n",
    "clinical_df_clean['Age'][clinical_df_clean['Age']<18]=np.nan\n",
    "\n",
    "# Gender/ Age/ Toilet/ Hand soap/ Reason for hospital admission/Co-morbidities/Antibiotics (Y/N)\n",
    "# - (missing values for same person - sample 199)\n",
    "clinical_df_clean['Gender'].describe()\n",
    "# Index of missing person\n",
    "clinical_df_clean[clinical_df_clean['Gender'].isnull()].index.tolist()\n",
    "\n",
    "# Dealing with anomalous value in BMI (missing sample 199 & 155 - anomaly)\n",
    "clinical_df_clean['BMI'].describe() # BMI = 2625? - Remove or replace with 26.25?\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "clinical_df_clean['BMI'][clinical_df_clean['BMI']>50]= np.nan\n",
    "\n",
    "# Urban/Rural - complete\n",
    "clinical_df_clean['Urban/Rural'].describe()\n",
    "\n",
    "# Smoker - Yes and Y - change to all Yes (missing sample 199)\n",
    "clinical_df_clean['Smoker (Y/N) & no.'].value_counts()\n",
    "clinical_df_clean['Smoker (Y/N) & no.'][clinical_df_clean['Smoker (Y/N) & no.']=='Y'] = 'Yes'\n",
    "\n",
    "# Lots of different reasons - most freq = 'Not hospitalised' (154), then 'Gastrointestinal' (17). \n",
    "# Some include mutliple diagnoses.\n",
    "clinical_df_clean['Reason for hospital admission'].value_counts()\n",
    "clinical_df_clean['Reason for hospital admission'][clinical_df_clean['Reason for hospital admission']=='Not Known']= None\n",
    "\n",
    "\n",
    "# Lots of different co-morbidites - most freq = 'No', then 'Epilepsy' - Could just change to yes or no?\n",
    "display(clinical_df_clean['Co-morbidities'].value_counts())\n",
    "clinical_df_clean[clinical_df_clean['BMI'].isnull()].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dd6e8f",
   "metadata": {},
   "source": [
    "# ML setup - feature & targey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c70c2188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import variaous sublibraries from sklearn\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import  compose, pipeline, preprocessing, linear_model, tree, ensemble, model_selection, metrics, multiclass, svm\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "# Feature variables\n",
    "features=['Age', 'Gender', 'BMI', 'Urban/Rural','Toilet (Y/N)', 'Hand soap', 'Smoker (Y/N) & no.',\n",
    "   'Reason for hospital admission', 'Co-morbidities', 'Antibiotics (Y/N)']\n",
    "\n",
    "# use_variables=list(glycome_clean_df.columns)\n",
    "\n",
    "### Fearture - All variables - Early integration\n",
    "# Concat cleaned datasets\n",
    "df_cleaned = res = pd.concat([clinical_df_clean, glycome_df, scfa_df], axis=1).sort_index()\n",
    "# Getting only features\n",
    "X = df_cleaned.iloc[:,1:]\n",
    "\n",
    "# Target variable\n",
    "y = df_cleaned['Diarrheal/ Non Diarrheal']\n",
    "\n",
    "\n",
    "\n",
    "#################\n",
    "# Changing 'Reason for hospital admission' & 'Co-morbidities' to binary for simplicity\n",
    "X_simple = X.copy()\n",
    "# 'Reason for hospital admission'\n",
    "X_simple['Reason for hospital admission'] = pd.Series(np.where(X_simple['Reason for hospital admission'] == 'Not Hospitalised', 'Not Hospitalised', 'Yes'),\n",
    "          X_simple.index)\n",
    "X_simple.loc[[220, 218, 216, 198, 74], 'Reason for hospital admission'] = np.nan\n",
    "# 'Co-morbidities'\n",
    "X_simple['Co-morbidities'] = pd.Series(np.where(X_simple['Co-morbidities'] == 'No', 'No', 'Yes'),\n",
    "          X_simple.index)\n",
    "\n",
    "# Encoding variables into binary \n",
    "X_simple['Gender'] = X_simple.Gender.map({'M':0, 'F':1})\n",
    "X_simple['Urban/Rural'] = X_simple['Urban/Rural'].map({'Urban':0, 'Rural':1})\n",
    "X_simple['Toilet (Y/N)'] = X_simple['Toilet (Y/N)'].map({'No':0, 'Yes':1})\n",
    "X_simple['Hand soap'] = X_simple['Hand soap'].map({'No':0, 'Yes':1})\n",
    "X_simple['Smoker (Y/N) & no.'] = X_simple['Smoker (Y/N) & no.'].map({'No':0, 'Yes':1})\n",
    "X_simple['Reason for hospital admission'] = X_simple['Reason for hospital admission'].map({'Not Hospitalised':0, 'Yes':1})\n",
    "X_simple['Co-morbidities'] =X_simple['Co-morbidities'].map({'No':0, 'Yes':1})\n",
    "X_simple['Antibiotics (Y/N)'] = X_simple['Antibiotics (Y/N)'].map({'No':0, 'Yes':1})\n",
    "\n",
    "\n",
    "\n",
    "###################\n",
    "# Splitting data into test and train (pre-specified by Waleed split)\n",
    "# Test\n",
    "test_X = X_simple.loc[[1,4,9,19,23,29,30,36,43,44,64,67,83,86,87,105,108,115,119,127,130,131,133,134,140,153,155,\n",
    "                           158,159,174,175,178,180,185,192,194,207,208,213,214,215,221],:]\n",
    "test_y = y.loc[y.index.isin(test_X.index)]\n",
    "\n",
    "# Train\n",
    "train_X = X_simple.loc[~X.index.isin(test_X.index)]\n",
    "train_y = y.loc[~y.index.isin(test_X.index)]\n",
    "\n",
    "# Changing y values to 0 and 1\n",
    "train_y = train_y.replace({'Diarrheal' : 1, 'Non Diarrheal' : 0})\n",
    "test_y = test_y.replace({'Diarrheal' : 1, 'Non Diarrheal' : 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf3393d",
   "metadata": {},
   "source": [
    "# Pipeline - preprocessor & classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7157b88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing pipeline\n",
    "\n",
    "# control, which variables to use. \n",
    "use_variables = [\n",
    "    'age', \n",
    "    'sex', \n",
    "    'cp', \n",
    "    'trestbps', \n",
    "    'chol', \n",
    "    'fbs', \n",
    "    'restecg', \n",
    "    'thalach',\n",
    "    'exang', \n",
    "    'oldpeak', \n",
    "    'slope', \n",
    "    'ca', \n",
    "    'thal'\n",
    "]\n",
    "\n",
    "\n",
    "# Numeric - All\n",
    "numeric_features = list(glycome_df.columns) + list(scfa_df.columns)\n",
    "# numeric_features = [x for x in numeric_features if x in use_variables]\n",
    "numeric_transformer = pipeline.Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', preprocessing.StandardScaler())\n",
    "])\n",
    "\n",
    "\n",
    "### Count\n",
    "count_features = ['Age']\n",
    "count_transformer = pipeline.Pipeline(steps=[\n",
    "                                      ('imputer', KNNImputer(n_neighbors=1)),\n",
    "                                      ('scaler', preprocessing.StandardScaler())\n",
    "])\n",
    "# count_features = [x for x in count_features if x in use_variables]\n",
    "\n",
    "\n",
    "### Categorical\n",
    "categorical_features = ['Gender',\n",
    "                        'Urban/Rural',\n",
    "                        'Toilet (Y/N)',\n",
    "                        'Hand soap',\n",
    "                        'Smoker (Y/N) & no.',\n",
    "                        'Reason for hospital admission',\n",
    "                        'Co-morbidities',\n",
    "                        'Antibiotics (Y/N)'\n",
    "]\n",
    "\n",
    "# categorical_features = [x for x in categorical_features if x in use_variables]\n",
    "categorical_transformer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "\n",
    "\n",
    "# Preprocessor - simple All\n",
    "allvar_preprocessor = compose.ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('count', count_transformer, count_features),\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "276ae824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('count',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   KNNImputer(n_neighbors=1)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['Age']),\n",
       "                                                 ('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['Low-branching glycans (LB)',\n",
       "                                                   'High-branching glycans '\n",
       "                                                   '(HB)',\n",
       "                                                   'Neutral (not siaylated) '\n",
       "                                                   'glycans (S0)',\n",
       "                                                   'Monosia...\n",
       "                                                   '2-hydroxybutyrate',\n",
       "                                                   '2-methylbutyrate',\n",
       "                                                   'Acetate', 'Butyrate',\n",
       "                                                   'Caproate', 'Isobutyrate',\n",
       "                                                   'Isovalerate', 'Propionate',\n",
       "                                                   'Valerate']),\n",
       "                                                 ('cat',\n",
       "                                                  KNNImputer(n_neighbors=3),\n",
       "                                                  ['Gender', 'Urban/Rural',\n",
       "                                                   'Toilet (Y/N)', 'Hand soap',\n",
       "                                                   'Smoker (Y/N) & no.',\n",
       "                                                   'Reason for hospital '\n",
       "                                                   'admission',\n",
       "                                                   'Co-morbidities',\n",
       "                                                   'Antibiotics (Y/N)'])])),\n",
       "                ('classifier', RandomForestClassifier(random_state=1))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForest = pipeline.Pipeline(steps=[\n",
    "            ('preprocessor', allvar_preprocessor),\n",
    "            ('classifier', (ensemble.RandomForestClassifier(random_state = 1)))\n",
    "])\n",
    "\n",
    "RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4ec9b0",
   "metadata": {},
   "source": [
    "# Parameters for grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23d29a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for best parameter\n",
    "params = {\n",
    "    'classifier__n_estimators':             [5,10,20,30],\n",
    "    'classifier__criterion':                ['gini','entropy'],\n",
    "    'classifier__max_depth':                [4,5,7],\n",
    "    'classifier__min_samples_split':        [2,4,5,10],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecace29",
   "metadata": {},
   "source": [
    "# Grid search and ROC curve setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92c6070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_search(X_kf, y_kf,cv_object,cv_inner=5,scoring='roc_auc',out_dir='.',viz_plot=False):\n",
    "    \n",
    "    classes     = sorted(list(y_kf.unique()))\n",
    "    len_classes = len(classes)\n",
    "    y_bin       = preprocessing.label_binarize(y_kf, classes=classes)\n",
    "    #patch needed as label_binarize returns single valued lists for n = 2\n",
    "    if len_classes == 2:\n",
    "        bin_map = {0:[1,0],1:[0,1]}\n",
    "        y_bin = np.array(y_kf.map(bin_map).to_list())\n",
    "\n",
    "#     y_bin\n",
    "    n_classes = 1\n",
    "    print(n_classes)\n",
    "\n",
    "\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    grid_search = model_selection.GridSearchCV(RandomForest, \n",
    "                           params, \n",
    "                           cv=5, \n",
    "                           scoring='roc_auc')\n",
    "\n",
    "    result_hash = {\n",
    "    }\n",
    "\n",
    "    result_hash['n_classes'] = n_classes\n",
    "\n",
    "\n",
    "    for enumerated_i, (train, test) in enumerate(cv_object.split(X_kf, y_kf)):\n",
    "        e_i = enumerated_i\n",
    "        result_hash[e_i] = {}\n",
    "\n",
    "        \n",
    "        result_hash[e_i]['train']     = train\n",
    "        result_hash[e_i]['test']      = test\n",
    "        result_hash[e_i]['n_classes'] = n_classes\n",
    "        \n",
    "        \n",
    "        grid_search.fit(X_kf.iloc[train],  y_kf.iloc[train])\n",
    "\n",
    "        # print out the best model after this\n",
    "        print('Best params : {}'.format(grid_search.best_params_))\n",
    "        result_hash[e_i]['best_params_'] = grid_search.best_params_\n",
    "\n",
    "        # use best clasifier from internal grid\n",
    "        classifier = grid_search.best_estimator_\n",
    "        result_hash[e_i]['best_estimator_'] = grid_search.best_estimator_\n",
    "        \n",
    "        \n",
    "# #         # Feature importance\n",
    "# #         grid_search.best_estimator_[1][1].feature_importances_\n",
    "\n",
    "# #         Printing feature importance\n",
    "#         for feature_name,feature_importance in zip(X_kf.iloc[train].columns.values,grid_search.best_estimator_[1][1].feature_importances_):\n",
    "#             if feature_importance > 0.0:\n",
    "#                 print('{:20s}:{:3.4f}'.format(feature_name,feature_importance))\n",
    "\n",
    "        # Feature importance with df\n",
    "        df_importance = pd.DataFrame(list(zip(X_kf.iloc[train].columns.values,grid_search.best_estimator_[1][1].feature_importances_)),columns=['column_name','feature_importance'])\n",
    "        df_importance = df_importance.set_index(['column_name'])\n",
    "        df_importance.sort_values(['feature_importance'],ascending=False,inplace=True)\n",
    "        \n",
    "        \n",
    "        # we need prediction probabilities for computing a ROC curve\n",
    "        y_proba = classifier.predict_proba(X_kf.iloc[test])\n",
    "\n",
    "        y_test  = y_kf.iloc[test]\n",
    "        \n",
    "\n",
    "        result_hash[e_i]['X_test']       = X_kf.iloc[test]\n",
    "        result_hash[e_i]['y_test']       = y_test\n",
    "        result_hash[e_i]['y_test_proba'] = y_proba[:,1]\n",
    "        \n",
    "        \n",
    "        result_hash[e_i]['fpr']        = {}\n",
    "        result_hash[e_i]['tpr']        = {}\n",
    "        result_hash[e_i]['thrs']       = {}\n",
    "        result_hash[e_i]['auc']        = {}\n",
    "        result_hash[e_i]['feat_impor'] = {}\n",
    "\n",
    " \n",
    "        result_hash[e_i]['fpr'][0], result_hash[e_i]['tpr'][0],result_hash[e_i]['thrs'][0] = metrics.roc_curve(y_test, y_proba[:,1])\n",
    "\n",
    "        result_hash[e_i]['auc'][0] = metrics.auc(result_hash[e_i]['fpr'][0], result_hash[e_i]['tpr'][0])\n",
    "        \n",
    "        result_hash[e_i]['feat_impor'] = df_importance\n",
    "\n",
    "        print('auc', result_hash[e_i]['auc'])\n",
    "\n",
    "    return result_hash\n",
    "\n",
    "#0.23-patch\n",
    "#required as 0.23 does not have RocCurveDisplay.from_predictions implemented\n",
    "def RocCurveDisplay_from_predictions(\n",
    "#        cls,\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        *,\n",
    "        sample_weight=None,\n",
    "        drop_intermediate=True,\n",
    "        pos_label=None,\n",
    "        name=None,\n",
    "        ax=None,\n",
    "        **kwargs,\n",
    "    ):         \n",
    "    \n",
    "    fpr, tpr, _ = metrics.roc_curve(\n",
    "            y_true,\n",
    "            y_pred,\n",
    "            pos_label=pos_label,\n",
    "            sample_weight=sample_weight,\n",
    "            drop_intermediate=drop_intermediate,\n",
    "    )\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    name = \"Classifier\" if name is None else name\n",
    "    #pos_label = _check_pos_label_consistency(pos_label, y_true)\n",
    "\n",
    "    viz = metrics.RocCurveDisplay(\n",
    "            fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name=name, # pos_label=pos_label\n",
    "    )\n",
    "\n",
    "    return viz.plot(ax=ax, name=name, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703905bb",
   "metadata": {},
   "source": [
    "# K-fold cross validation and ROC/Feature importance charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cea6105d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Best params : {'classifier__criterion': 'gini', 'classifier__max_depth': 4, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 30}\n",
      "auc {0: 0.9711538461538461}\n",
      "Best params : {'classifier__criterion': 'entropy', 'classifier__max_depth': 5, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 30}\n",
      "auc {0: 0.9935897435897436}\n",
      "Best params : {'classifier__criterion': 'gini', 'classifier__max_depth': 7, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 30}\n",
      "auc {0: 0.9711538461538461}\n",
      "Best params : {'classifier__criterion': 'gini', 'classifier__max_depth': 5, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 20}\n",
      "auc {0: 0.9813664596273292}\n",
      "Best params : {'classifier__criterion': 'entropy', 'classifier__max_depth': 7, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 30}\n",
      "auc {0: 0.9596273291925466}\n",
      "Best params : {'classifier__criterion': 'gini', 'classifier__max_depth': 5, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 30}\n",
      "auc {0: 0.9933110367892977}\n",
      "1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hc/c0m0nxk93qb_ggmlvbk7wtbh0000gn/T/ipykernel_48760/1611550584.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m## Mean feature importance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m df_mean_feat_impor = pd.DataFrame(list(zip(X_kf.iloc[train].columns.values,[0]*34)),\n\u001b[0m\u001b[1;32m     44\u001b[0m                                columns=['column_name','feature_importance']).set_index(['column_name'])\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# import variaous sublibraries from sklearn\n",
    "from sklearn import  compose, pipeline, preprocessing, linear_model, tree, ensemble, model_selection, metrics, multiclass, svm\n",
    "\n",
    "\n",
    "n_splits = 6\n",
    "cv_object = model_selection.StratifiedKFold(n_splits=n_splits,shuffle=True,random_state=0)\n",
    "\n",
    "X_kf = X_simple.copy() # and (x not in missing_cols)]\n",
    "y_kf = y.replace({'Diarrheal' : 1, 'Non Diarrheal' : 0})\n",
    "\n",
    "\n",
    "classes   = sorted(list(y.unique()),)\n",
    "\n",
    "res = {}\n",
    "\n",
    "clfs = {\n",
    "    'RandomForest':{\n",
    "        'clf': RandomForest\n",
    "    }\n",
    "}\n",
    "\n",
    "# for i in [x for x in clfs.keys()]:\n",
    "#     print(i)\n",
    "\n",
    "result_hash = run_grid_search(X_kf, \n",
    "                y_kf,\n",
    "                cv_object,\n",
    "                cv_inner=5,\n",
    "                scoring='roc_auc',\n",
    "        )\n",
    "res['Random Forest']  = result_hash\n",
    "\n",
    "n_classes = result_hash['n_classes']\n",
    "print(n_classes)\n",
    "\n",
    "\n",
    "## Mean feature importance\n",
    "df_mean_feat_impor = pd.DataFrame(list(zip(X_kf.iloc[train].columns.values,[0]*34)),\n",
    "                               columns=['column_name','feature_importance']).set_index(['column_name'])\n",
    "\n",
    "for k in [x for x in result_hash if x not in ['n_classes']]:\n",
    "    \n",
    "    df_mean_feat_impor = df_mean_feat_impor + result_hash[k]['feat_impor']\n",
    "\n",
    "df_mean_feat_impor['feature_importance'] = df_mean_feat_impor['feature_importance']/n_splits\n",
    "df_mean_feat_impor.sort_values(['feature_importance'],ascending=False,inplace=True)\n",
    "\n",
    "\n",
    "## plotting feature importance\n",
    "plt.figure(figsize=(20,10))\n",
    "import seaborn as sns\n",
    "sns.barplot(x='column_name',y='feature_importance',data=df_mean_feat_impor.iloc[0:10,:].reset_index(),palette='muted')\n",
    "ticks_information = plt.xticks(rotation=65)\n",
    "display()\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,n_classes,figsize=((n_classes)*11,10))\n",
    "\n",
    "## plot roc curves for each class\n",
    "for n_class in range(n_classes):\n",
    "    print(n_class)\n",
    "    det_curve = None\n",
    "\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "\n",
    "    for k in [x for x in result_hash if x not in ['n_classes']]:\n",
    "\n",
    "        local_ax = None\n",
    "        if det_curve:\n",
    "            local_ax = det_curve.ax_\n",
    "        else:\n",
    "            local_ax = ax\n",
    "\n",
    "        #det_curve = metrics.RocCurveDisplay.from_predictions(\n",
    "        det_curve = RocCurveDisplay_from_predictions(\n",
    "                result_hash[k]['y_test'],\n",
    "                result_hash[k]['y_test_proba'],\n",
    "                name='ROC fold {}'.format(str(k+1).zfill(2)),\n",
    "                pos_label = 1,\n",
    "                alpha=0.3, \n",
    "                lw=1, \n",
    "                ax=local_ax,\n",
    "            )\n",
    "        local_ax = det_curve.ax_\n",
    "\n",
    "        interp_tpr = np.interp(mean_fpr, det_curve.fpr, det_curve.tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(det_curve.roc_auc)\n",
    "\n",
    "    class_ax = det_curve.ax_\n",
    "    class_ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',label='default', alpha=.8)\n",
    "\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = metrics.auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "\n",
    "    class_ax.plot(mean_fpr, \n",
    "        mean_tpr, \n",
    "        color='b',\n",
    "        label=r'Mean ROC (AUC = {:0.3f} $\\pm$ {:0.3f})'.format(mean_auc, std_auc),\n",
    "        lw=2, \n",
    "        alpha=.8)\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    class_ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "    class_ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],\n",
    "        title='Receiver operating characteristic - Classifiers: {}s (class={})'.format('Random Forest',classes[1]))\n",
    "    class_ax.legend(loc=\"lower right\")\n",
    "    class_ax.set_xlabel('False Positive Rate')\n",
    "    class_ax.set_ylabel('True Positive Rate')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6110eb56",
   "metadata": {},
   "source": [
    "# Trial & error code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d0a8a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train= list(range(0,34,1))\n",
    "\n",
    "fake = np.array([0]*34)\n",
    "\n",
    "mean_feat_impor = pd.DataFrame(list(zip(X_kf.iloc[train].columns.values,[0]*34)),columns=['column_name','feature_importance']).set_index(['column_name'])\n",
    "\n",
    "# mean_feat_impor + result_hash[0]['feat_impor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "528635b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
